{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10a07dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import threading\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a8244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"bucket/dataset_customs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af78c2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bucket/dataset_customs/export', 'bucket/dataset_customs/import']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_ex_dir = [os.path.join(base,x) for x in os.listdir(base) if os.path.isdir(os.path.join(base,x))]\n",
    "im_ex_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d27584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(file_paths):\n",
    "    if len(file_paths)>0:\n",
    "        return file_paths[0].split('/')[-3]\n",
    "    return \"\"\n",
    "\n",
    "def group_file_names(file_paths):\n",
    "    groups = {}\n",
    "    file_names = [(fp.split('/')[-1].split('-')[0], fp) for fp in file_paths]\n",
    "    for year, f_path in file_names:\n",
    "        if year in groups:\n",
    "            groups[year].append(f_path)\n",
    "        else:\n",
    "            groups[year] = [f_path]\n",
    "    for elm in groups:\n",
    "        groups[elm].sort()\n",
    "    sort_groups = sorted(groups.items(), key=lambda key: key[0])\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'year':elm[0],\n",
    "            'type':get_category(elm[1]),\n",
    "            'data':elm[1]\n",
    "        } \n",
    "        for elm in sort_groups\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3ee42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [elm for elm in calendar.month_abbr]\n",
    "months_dict = { elm:months.index(elm) for elm in months}\n",
    "months_dict['Sept'] = 9\n",
    "def month2int(month):\n",
    "    return months_dict[month]\n",
    "\n",
    "def convert2com(name):\n",
    "    month_name, year = name.replace('(',' ').replace(')','').split(' ')[-2:]\n",
    "    month = month2int(month_name)\n",
    "    return \"{}-{:02d}\".format(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be0e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_out = \"bucket/merge_dataset_customs\"\n",
    "if not os.path.exists(base_out):\n",
    "    os.mkdir(base_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6b038",
   "metadata": {},
   "source": [
    "# Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd3f29",
   "metadata": {},
   "source": [
    "in this case threading slower than single thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6facd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_files(key, data):\n",
    "#     sub_outpath = os.path.join(base_out, key)\n",
    "#     if not os.path.exists(sub_outpath):\n",
    "#         os.makedirs(sub_outpath)\n",
    "#     merge_df_name = \"{}.csv\".format(data[0].split('/')[-2])\n",
    "#     df = None\n",
    "#     for index, f_path in enumerate(data):\n",
    "#         df_tmp = pd.read_csv(f_path)\n",
    "#         columns_acc = list(df_tmp.columns)[1:3]\n",
    "#         df_tmp = df_tmp[columns_acc]\n",
    "#         df_tmp = df_tmp.rename(columns={columns_acc[-1]:convert2com(columns_acc[-1])})\n",
    "#         if index==0:\n",
    "#             df = df_tmp\n",
    "#         else:\n",
    "#             df = pd.merge(df, df_tmp, how='outer')\n",
    "#     df.to_csv(os.path.join(sub_outpath, merge_df_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab40915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t = []\n",
    "# for data_type in im_ex_dir:\n",
    "#     category_paths = [os.path.join(data_type, x) for x in os.listdir(data_type) if os.path.isdir(os.path.join(data_type, x))]\n",
    "#     category_paths.sort()\n",
    "#     for category_path in tqdm(category_paths):\n",
    "#         files_path = [os.path.join(category_path, x) for x in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, x))]\n",
    "#         group_file = group_file_names(files_path)\n",
    "#         for group in group_file:\n",
    "#             x = threading.Thread(target=merge_files, args=(group, group_file[group]))\n",
    "#             t.append(x)\n",
    "#             x.start()\n",
    "#         for thread in t:\n",
    "#             thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5047f",
   "metadata": {},
   "source": [
    "# Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5068e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb7603c7c7e474088524581341b06a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8afadd9b0ae4a76a0e18db14a688845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''single thread'''\n",
    "for data_type in im_ex_dir:\n",
    "    category_paths = [os.path.join(data_type, x) for x in os.listdir(data_type) if os.path.isdir(os.path.join(data_type, x))]\n",
    "    category_paths.sort()\n",
    "    for category_path in tqdm(category_paths):\n",
    "        files_path = [os.path.join(category_path, x) for x in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, x))]\n",
    "        group_file = group_file_names(files_path) \n",
    "        for datas in group_file:\n",
    "            category = datas['type']\n",
    "            key = datas['year']\n",
    "            data = datas['data']\n",
    "            sub_outpath = os.path.join(base_out, category, key)\n",
    "            if not os.path.exists(sub_outpath):\n",
    "                os.makedirs(sub_outpath)\n",
    "            merge_df_name = \"{}.csv\".format(data[0].split('/')[-2])\n",
    "            df = None\n",
    "            for index, f_path in enumerate(data):\n",
    "                try:\n",
    "                    df_tmp = pd.read_csv(f_path)\n",
    "                    columns_acc = list(df_tmp.columns)[1:3]\n",
    "                    df_tmp = df_tmp[columns_acc]\n",
    "                    df_tmp = df_tmp.rename(columns={columns_acc[-1]:convert2com(columns_acc[-1])})\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if index==0:\n",
    "                    df = df_tmp\n",
    "                else:\n",
    "                    df = pd.merge(df, df_tmp, how='outer')\n",
    "            df.to_csv(os.path.join(sub_outpath, merge_df_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12898d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b25c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3c81e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dirs = []\n",
    "base_out_dirs = [os.path.join(base_out,x) for x in os.listdir(base_out) if os.path.isdir(os.path.join(base_out,x))]\n",
    "for base_out_dir in base_out_dirs:\n",
    "    list_dir = [os.path.join(base_out_dir, x) for x in os.listdir(base_out_dir) if len(x)==4]\n",
    "    list_dir.sort()\n",
    "    out_dirs += list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4ddbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c219f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files after merge : 52,647\n"
     ]
    }
   ],
   "source": [
    "all_files_path = []\n",
    "for out_dir in out_dirs:\n",
    "    all_files_path += [os.path.join(out_dir, x) for x in os.listdir(out_dir) if os.path.isfile(os.path.join(out_dir, x))]\n",
    "print(\"Total files after merge : {:,}\".format(len(all_files_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfa181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
